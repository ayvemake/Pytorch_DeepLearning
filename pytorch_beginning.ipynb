{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0b19f8",
   "metadata": {},
   "source": [
    "PYTORCH WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14be60",
   "metadata": {},
   "source": [
    "CUDA AND PYTORCH INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9a8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Devrait retourner True\n",
    "print(torch.cuda.get_device_name(0))  # Nom de ton GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0118cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6636, 0.2245, 0.8721],\n",
      "        [0.9764, 0.0721, 0.7391],\n",
      "        [0.9034, 0.7213, 0.4648]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Vérifie que CUDA est disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # GPU\n",
    "else:\n",
    "    device = torch.device('cpu')  # Si le GPU n'est pas disponible\n",
    "\n",
    "# Exemple avec un tensor\n",
    "x = torch.rand(3, 3)\n",
    "x = x.to(device)  # Déplace le tensor vers le GPU ou CPU\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02aa0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898aceea",
   "metadata": {},
   "source": [
    "## TENSORS\n",
    "### creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d58be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(12)\n",
    "print(scalar)\n",
    "print(scalar.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234cf3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15378e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 12])\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([12, 12])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "vector.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8f7846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [2, 1]])\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[4,3], \n",
    "                       [2,1]])\n",
    "print(matrix)\n",
    "print(matrix.ndim)\n",
    "matrix.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62ab18",
   "metadata": {},
   "source": [
    "## RANDOM TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534bcc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3980, 0.7071, 0.7591, 0.2979, 0.3084],\n",
      "        [0.0462, 0.6833, 0.2097, 0.9366, 0.4147],\n",
      "        [0.2431, 0.9437, 0.6881, 0.6032, 0.3431]])\n",
      "2\n",
      "torch.Size([3, 5])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "2\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "2\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,5)\n",
    "print(random_tensor)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)\n",
    "\n",
    "\n",
    "## ZEROS AND ONES\n",
    "zeros = torch.zeros(2,3)\n",
    "print(zeros)\n",
    "print(zeros.ndim)\n",
    "print(zeros.shape)\n",
    "\n",
    "ones = torch.ones(2,3)\n",
    "print(ones)\n",
    "print(ones.ndim)\n",
    "print(ones.shape)\n",
    "\n",
    "## TENSOR OPERATIONS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a725df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7787, 0.5484, 0.3318,  ..., 0.3915, 0.8521, 0.5942],\n",
      "         [0.9205, 0.7718, 0.7938,  ..., 0.1863, 0.8433, 0.9460],\n",
      "         [0.7553, 0.7955, 0.5494,  ..., 0.9207, 0.0977, 0.6067],\n",
      "         ...,\n",
      "         [0.4971, 0.9685, 0.6206,  ..., 0.6237, 0.8038, 0.6627],\n",
      "         [0.3025, 0.4981, 0.6368,  ..., 0.8259, 0.2747, 0.3841],\n",
      "         [0.9102, 0.0333, 0.7872,  ..., 0.3619, 0.1149, 0.6416]],\n",
      "\n",
      "        [[0.4179, 0.7078, 0.7996,  ..., 0.4122, 0.0250, 0.6900],\n",
      "         [0.4118, 0.6195, 0.9222,  ..., 0.0312, 0.4778, 0.4755],\n",
      "         [0.0191, 0.0844, 0.1620,  ..., 0.6187, 0.7088, 0.0678],\n",
      "         ...,\n",
      "         [0.4553, 0.5928, 0.2206,  ..., 0.4003, 0.8230, 0.7292],\n",
      "         [0.1319, 0.2008, 0.0669,  ..., 0.7826, 0.4806, 0.1229],\n",
      "         [0.2591, 0.8477, 0.5676,  ..., 0.8150, 0.5709, 0.1516]],\n",
      "\n",
      "        [[0.3983, 0.7761, 0.5617,  ..., 0.9986, 0.1315, 0.2160],\n",
      "         [0.7286, 0.3689, 0.0082,  ..., 0.6606, 0.3197, 0.4171],\n",
      "         [0.4819, 0.9736, 0.5245,  ..., 0.5799, 0.7680, 0.7508],\n",
      "         ...,\n",
      "         [0.7764, 0.6151, 0.5060,  ..., 0.4872, 0.5057, 0.9615],\n",
      "         [0.8386, 0.7555, 0.8910,  ..., 0.4120, 0.4959, 0.9306],\n",
      "         [0.3179, 0.8181, 0.3469,  ..., 0.5398, 0.8164, 0.5804]]])\n",
      "3\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(3, 224, 224)\n",
    "print(random_image_size_tensor)\n",
    "print(random_image_size_tensor.ndim)\n",
    "print(random_image_size_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0622d0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f84bc",
   "metadata": {},
   "source": [
    "## RANGE OF TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd30c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_twenty_a =torch.arange(0,20) #range from 1 to 21\n",
    "print(one_to_twenty_a)\n",
    "one_to_twenty_b = torch.arange(start=1, end=21, step=1)\n",
    "print(one_to_twenty_b)\n",
    "# do not forget -1 increment \n",
    "torch.zeros_like(one_to_twenty_a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad95f4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3000, 3.2000, 4.5000], device='cuda:0', requires_grad=True)\n",
      "1\n",
      "torch.Size([3])\n",
      "tensor([2.3008, 3.1992, 4.5000], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "float_tensor = torch.tensor([2.3, 3.2, 4.5], \n",
    "                            dtype=torch.float32, # by default is float32\n",
    "                            device=device, \n",
    "                            requires_grad=True)\n",
    "print(float_tensor)\n",
    "print(float_tensor.ndim)\n",
    "print(float_tensor.shape)\n",
    "\n",
    "float_16_tensor = float_tensor.to(torch.float16)\n",
    "print(float_16_tensor)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef17473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.int32\n",
      "tensor([1., 2., 3.])\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#convert int32 to float32\n",
    "int_tensor = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "print(int_tensor)\n",
    "print(int_tensor.dtype)\n",
    "\n",
    "int_to_float = int_tensor.to(torch.float32)\n",
    "print(int_to_float)\n",
    "print(int_to_float.dtype)\n",
    "\n",
    "mixed_tensor = int_tensor*int_to_float\n",
    "print(mixed_tensor.dtype)\n",
    "# .shape is an attribute, and .size is a function \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a1921",
   "metadata": {},
   "source": [
    "## Tensors operations\n",
    "### addition, subtraction, multiplication, division, matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46791496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from tensor([1, 2, 3])\n",
      "tensor + 1: tensor([2, 3, 4])\n",
      "tensor - 1: tensor([0, 1, 2])\n",
      "tensor * 2: tensor([2, 4, 6])\n",
      "tensor / 2: tensor([0.5000, 1.0000, 1.5000])\n",
      "tensor * tensor: tensor([1, 4, 9])\n",
      "tensor / tensor: tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print('from %s' % tensor)\n",
    "print('tensor + 1: %s' % (tensor + 1))\n",
    "print('tensor - 1: %s' % (tensor - 1))\n",
    "print('tensor * 2: %s' % (tensor * 2))\n",
    "print('tensor / 2: %s' % (tensor / 2))\n",
    "print('tensor * tensor: %s' % (tensor * tensor))\n",
    "print('tensor / tensor: %s' % (tensor / tensor))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ffebab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from tensor([1, 2, 3]) we apply element wise, dot product and matrix multiplication\n",
      "with * operator: element wise multiplication gives tensor([1, 4, 9])\n",
      "CPU times: user 359 μs, sys: 48 μs, total: 407 μs\n",
      "Wall time: 296 μs\n",
      "with @ operator: dot product gives tensor(14)\n",
      "CPU times: user 129 μs, sys: 0 ns, total: 129 μs\n",
      "Wall time: 131 μs\n",
      "with the matmul function, matrix multiplication gives tensor(14)\n",
      "CPU times: user 87 μs, sys: 0 ns, total: 87 μs\n",
      "Wall time: 88.7 μs\n",
      "--> use matmul for speed increase and better performance\n"
     ]
    }
   ],
   "source": [
    "print('from %s' % tensor, 'we apply element wise, dot product and matrix multiplication')\n",
    "%time print('with * operator: element wise multiplication gives %s' % (tensor*tensor)) # element wise multiplication\n",
    "%time print('with @ operator: dot product gives %s' % (tensor@tensor)) # dot product\n",
    "%time print('with the matmul function, matrix multiplication gives %s' % (tensor.matmul(tensor))) # matrix multiplication\n",
    "print('--> use matmul for speed increase and better performance')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c96ab",
   "metadata": {},
   "source": [
    "## Inner dimmensions must match, resulting matrix has the following shape: (m, n) @ (n, p) = (m, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b729f638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "CPU times: user 1.17 ms, sys: 25 μs, total: 1.2 ms\n",
      "Wall time: 997 μs\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "CPU times: user 286 μs, sys: 0 ns, total: 286 μs\n",
      "Wall time: 186 μs\n",
      "---> it is better to use matmul for speed increase\n",
      "---> for transpose, use .T at the end of the tensor, Tensor_B.T\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4]])\n",
    "tensor_B = torch.tensor([[5,6],\n",
    "                        [7,8]])\n",
    "%time print(torch.mm(tensor_A, tensor_B))\n",
    "%time print(tensor_A.matmul(tensor_B))\n",
    "print('---> it is better to use matmul for speed increase')\n",
    "print('---> for transpose, use .T at the end of the tensor, Tensor_B.T')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7684c78",
   "metadata": {},
   "source": [
    "## Finding min, max, mean, sum, argmin, argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8898fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(0)\n",
      "tensor(90)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "print(x)\n",
    "print(x.min())\n",
    "print(x.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a61e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the mean, use .mean() with float32 or float16, long does not work\n",
      "torch.mean(x.dtype(float32))\n",
      "---> tensor(45.)\n"
     ]
    }
   ],
   "source": [
    "print('For the mean, use .mean() with float32 or float16, long does not work')\n",
    "print('torch.mean(x.dtype(float32))')\n",
    "print('--->', torch.mean(x.type(torch.float32)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62259fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sum, use .sum()\n",
      "---> torch.sum(x)) = tensor(450)\n",
      "---> x.sum() = tensor(450) also works\n"
     ]
    }
   ],
   "source": [
    "print('For the sum, use .sum()')\n",
    "print('---> torch.sum(x)) =', torch.sum(x))\n",
    "print('---> x.sum() =', x.sum(), 'also works')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f823a01",
   "metadata": {},
   "source": [
    "## argmin and argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bebf4952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(0) ---> returns the index of the minimum value\n",
      "tensor(9) ---> returns the index of the maximum value\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.argmin(), '---> returns the index of the minimum value')\n",
    "print(x.argmax(), '---> returns the index of the maximum value')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed029c0",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing, unsqueezing\n",
    "* reshape: reshapes a tensor to a defined shape\n",
    "* view: returns a view of an input tensor of certain shape but keeps the same memory as original tensor\n",
    "* squeeze: removes all the 1 dimensions from the shape of a tensor\n",
    "* unsqueeze: adds an extra dimension to the shape of a tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75d6b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([9])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 9]) ---> use of reshape, see brackets\n",
      "CPU times: user 18 μs, sys: 4 μs, total: 22 μs\n",
      "Wall time: 24.8 μs\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 9]) ---> use of view, see brackets\n",
      "CPU times: user 36 μs, sys: 8 μs, total: 44 μs\n",
      "Wall time: 46 μs\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.reshape(1,9))\n",
    "%time print(x.reshape(1,9).shape, '---> use of reshape, see brackets')\n",
    "print(x.view(1,9))\n",
    "%time print(x.view(1,9).shape, '---> use of view, see brackets')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bfb44cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([1, 9])\n",
      "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([1, 9])\n",
      "tensor([5, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "---> stack tensors vertically, use torch.stack\n",
      "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [5, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [5, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([3, 9])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(1,9)\n",
    "print(z, z.shape)\n",
    "z[:, 0] = 5\n",
    "print(z, z.shape)\n",
    "print(x)\n",
    "print('---> stack tensors vertically, use torch.stack')\n",
    "x_stacked = torch.stack([x,x,x])\n",
    "print(x_stacked, x_stacked.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03a731",
   "metadata": {},
   "source": [
    "## use of squeeze and unsqueeze methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5bcb1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 9])\n",
      "---> use of squeeze\n",
      "tensor([5, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([9])\n",
      "One dimension is removed, see brackets\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x_reshaped = x.reshape(1,9)\n",
    "print(x_reshaped)\n",
    "print(x_reshaped.shape)\n",
    "print('---> use of squeeze')\n",
    "print(x_reshaped.squeeze())\n",
    "print(x_reshaped.squeeze().shape)\n",
    "print('One dimension is removed, see brackets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d52e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueeze adds an extra dimension to a target tensor at a specific dim\n",
      "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "---> for dim=0:  tensor([[[5, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
      "shape:  torch.Size([1, 1, 9])\n",
      "---> for dim=1:  tensor([[[5, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
      "shape:  torch.Size([1, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "print('unsqueeze adds an extra dimension to a target tensor at a specific dim')\n",
    "print(x_reshaped)\n",
    "print('---> for dim=0: ',x_reshaped.unsqueeze(dim=0))\n",
    "print('shape: ',x_reshaped.unsqueeze(dim=0).shape)\n",
    "print('---> for dim=1: ',x_reshaped.unsqueeze(dim=1))\n",
    "print('shape: ',x_reshaped.unsqueeze(dim=1).shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ef73d",
   "metadata": {},
   "source": [
    "## Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7f8a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n",
      "shifts axis 0->1, 1->2, 2->0\n",
      "torch.Size([3, 224, 224])\n",
      "--> SHARES THE SAME MEMORY AS THE ORIGINAL TENSOR\n",
      "x_original[0,0,0] = tensor(100.)\n",
      "x_permuted[0,0,0] = tensor(100.) ---> same value without changing it\n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "print(x_original.shape)\n",
    "x_permuted = x_original.permute(2,0,1) \n",
    "print('shifts axis 0->1, 1->2, 2->0')\n",
    "print(x_permuted.shape)\n",
    "print('--> SHARES THE SAME MEMORY AS THE ORIGINAL TENSOR')\n",
    "x_original[0,0,0] = 100\n",
    "print('x_original[0,0,0] =', x_original[0,0,0])\n",
    "print('x_permuted[0,0,0] =', x_permuted[0,0,0], '---> same value without changing it')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec1659",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85359f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) ---> print full tensor\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) ---> print first dimension\n",
      "tensor([1, 2, 3]) ---> print first dimension, first element\n",
      "tensor(1) ---> print first dimension, first element, first element\n",
      "1 ---> returns the value of the tensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1, 3, 3)\n",
    "print(x, '---> print full tensor')\n",
    "print(x[0], '---> print first dimension')\n",
    "print(x[0,0], '---> print first dimension, first element')\n",
    "print(x[0,0,0], '---> print first dimension, first element, first element')\n",
    "print(x[0,0,0].item(), '---> returns the value of the tensor')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2001095",
   "metadata": {},
   "source": [
    "## Indexing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "357a8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "x[0][0] is the same as x[0,0,:]\n"
     ]
    }
   ],
   "source": [
    "print(x[0][0])\n",
    "print(x[0,0,:])\n",
    "print('x[0][0] is the same as x[0,0,:]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ecb3f",
   "metadata": {},
   "source": [
    "## PyTorch and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "145062f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "--> when converting from numpy to pytorch, the data type is float64, need to specity to float32\n",
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n",
      "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(1.0,10.0)\n",
    "print(array)\n",
    "tensor = torch.from_numpy(array)\n",
    "print('--> when converting from numpy to pytorch, the data type is float64, need to specity to float32')\n",
    "print(tensor)\n",
    "array = tensor.numpy()\n",
    "print(array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc22d04",
   "metadata": {},
   "source": [
    "## Adding value to tensor and array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76540dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "--> adding value to array does not change tensor\n",
      "---> converting tensor to numpy, the data type is float32 again\n"
     ]
    }
   ],
   "source": [
    "array = array + 1\n",
    "print(array)\n",
    "print(tensor)\n",
    "print('--> adding value to array does not change tensor')\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor\n",
    "print('---> converting tensor to numpy, the data type is float32 again')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a0747",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "### To reduce randomness, set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c9784d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6631, 0.3612, 0.2596, 0.3011],\n",
      "        [0.9522, 0.8597, 0.9538, 0.1919],\n",
      "        [0.7623, 0.1937, 0.6029, 0.4315]])\n",
      "tensor([[0.1974, 0.1207, 0.4719, 0.3783],\n",
      "        [0.2016, 0.4390, 0.0036, 0.6808],\n",
      "        [0.6630, 0.2706, 0.8792, 0.2734]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "--> random tensor is not reproducible\n"
     ]
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)\n",
    "print('--> random tensor is not reproducible')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0444a56",
   "metadata": {},
   "source": [
    "### Random but reproducible tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c9815f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "--> random tensor is reproducible, we have to set the seed before the tensor is created\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 22\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "print(random_tensor_A == random_tensor_B)\n",
    "print('--> random tensor is reproducible, we have to set the seed before the tensor is created')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89705f81",
   "metadata": {},
   "source": [
    "### Running on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cf31723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 17 16:00:36 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8               6W /  35W |    105MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1814      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A     14240      C   .../ayvemake/Desktop/myenv/bin/python3       94MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e618a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "750f6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> transfer to GPU\n",
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('--> transfer to GPU')\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu, tensor_on_gpu.device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92cca6",
   "metadata": {},
   "source": [
    "### If tensor on GPU, can't transform it to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f33ed2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] cpu\n"
     ]
    }
   ],
   "source": [
    "tensor_back_on_gpu = tensor_on_gpu.cpu().numpy()\n",
    "print(tensor_back_on_gpu, tensor_back_on_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
